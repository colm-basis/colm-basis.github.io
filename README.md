# Introduction

This is the repository that contains the project webpage for the COLM 2025 paper:

**Bootstrapping Visual Assistant Development with Situated Interaction Simulation**  
Yichi Zhang<sup>1</sup>, Run Peng<sup>1</sup>, Lingyun Wu<sup>1</sup>, Yinpei Dai<sup>1</sup>, Xuweiyi Chen<sup>2</sup>, Qiaozi Gao<sup>3</sup>, Joyce Chai<sup>1</sup>  
<sup>1</sup>University of Michigan, <sup>2</sup>University of Virginia, <sup>3</sup>Amazon  
{zhangyic, roihn, chaijy}@umich.edu

The paper presents a simulation-based framework to accelerate and scale the development of proactive visual assistants.

The website is based on the [Nerfies website template](https://nerfies.github.io).

---

## Website License

<a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-sa/4.0/88x31.png" /></a>  
This work is licensed under a [Creative Commons Attribution-ShareAlike 4.0 International License](http://creativecommons.org/licenses/by-sa/4.0/).